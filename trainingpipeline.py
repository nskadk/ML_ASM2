# -*- coding: utf-8 -*-
"""TrainingPipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15_jT4VSIqHkxU7nwgmzC-v1Qr6tC68kx
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import json
import random
import time
import tempfile
import shutil
from datetime import datetime
import tensorflow as tf
from tensorflow import keras
from tqdm.notebook import tqdm
from tensorflow.keras import layers
from tensorflow.keras.applications import EfficientNetV2M, InceptionResNetV2, InceptionV3, Xception, DenseNet201, VGG19, ResNet101V2
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, Callback
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    roc_auc_score, f1_score, r2_score, mean_squared_error, mean_absolute_error,
    roc_curve, auc
)
from tabulate import tabulate
from sklearn.preprocessing import label_binarize

# Set seeds for reproducibility
SEED = 42
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        # Set memory growth to avoid taking all GPU memory
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)
os.environ['PYTHONHASHSEED'] = str(SEED)
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)
print("GPU Available: ", tf.config.list_physical_devices('GPU'))

# Enable mixed precision training for faster performance on NVIDIA GPUs
tf.keras.mixed_precision.set_global_policy('mixed_float16')
print("Mixed precision policy set to: ", tf.keras.mixed_precision.global_policy())

# Configuration
CONFIG = {
    'preprocessed_data_dir': './drive/MyDrive/Colab Notebooks/Machine Learning - ASM 3/processed_dataset/preprocessed_deduplicated',
    'metadata_path': 'meta_train.csv',
    'output_dir': './drive/MyDrive/Colab Notebooks/Machine Learning - ASM 3/final_training_results',
    'predict_dataset_dir': './drive/MyDrive/Colab Notebooks/Machine Learning - ASM 3/preprocessed_test_images',
    'img_size': (224, 224),
    'batch_size': 32,
    'epochs': 70,
    'learning_rate': 0.001,
    'train_split': 0.7,
    'val_split': 0.15,
    'test_split': 0.15,
    'random_state': SEED
}

# Create output directories
os.makedirs(CONFIG['output_dir'], exist_ok=True)
os.makedirs(os.path.join(CONFIG['output_dir'], 'models'), exist_ok=True)
os.makedirs(os.path.join(CONFIG['output_dir'], 'plots'), exist_ok=True)
os.makedirs(os.path.join(CONFIG['output_dir'], 'metrics'), exist_ok=True)

def count_total_samples(data_dir):
    """
    Count the total number of images in the dataset directory

    Args:
        data_dir: Path to the dataset directory

    Returns:
        total_samples: Total number of images found
    """
    total_samples = 0

    # Walk through all directories
    for root, dirs, files in os.walk(data_dir):
        # Count image files in current directory
        image_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        total_samples += len(image_files)

    return total_samples

# Usage
total_samples = count_total_samples(CONFIG['preprocessed_data_dir'])
print(f"Total samples in dataset: {total_samples}")

# Calculate steps_per_epoch
CONFIG['steps_per_epoch'] = int(total_samples * CONFIG['train_split']) // CONFIG['batch_size']
print(f"Steps per epoch: {CONFIG['steps_per_epoch'] }")

#####################################################
#                                                   #
#             CBAM ATTENTION MECHANISM              #
#                                                   #
#####################################################

# CBAM (Convolutional Block Attention Module) implementation
def channel_attention(input_feature, ratio=8):
    """Channel attention module"""
    channel = input_feature.shape[-1]

    # Shared MLP
    shared_layer_one = layers.Dense(channel // ratio,
                                    activation='relu',
                                    kernel_initializer='he_normal',
                                    use_bias=True,
                                    bias_initializer='zeros')
    shared_layer_two = layers.Dense(channel,
                                   kernel_initializer='he_normal',
                                   use_bias=True,
                                   bias_initializer='zeros')

    # Average pooling
    avg_pool = layers.GlobalAveragePooling2D()(input_feature)
    avg_pool = layers.Reshape((1, 1, channel))(avg_pool)
    avg_pool = shared_layer_one(avg_pool)
    avg_pool = shared_layer_two(avg_pool)

    # Max pooling
    max_pool = layers.GlobalMaxPooling2D()(input_feature)
    max_pool = layers.Reshape((1, 1, channel))(max_pool)
    max_pool = shared_layer_one(max_pool)
    max_pool = shared_layer_two(max_pool)

    # Attention weights
    cbam_feature = layers.Add()([avg_pool, max_pool])
    cbam_feature = layers.Activation('sigmoid')(cbam_feature)

    return layers.Multiply()([input_feature, cbam_feature])

def spatial_attention(input_feature, kernel_size=7):
    """Spatial attention module with explicit output shapes for Lambda layers"""
    # Define output shape functions
    def avg_pool_output_shape(input_shape):
        return input_shape[0], input_shape[1], input_shape[2], 1

    def max_pool_output_shape(input_shape):
        return input_shape[0], input_shape[1], input_shape[2], 1

    # Generate feature descriptor on the spatial dimension with explicit output shapes
    avg_pool = layers.Lambda(
        lambda x: tf.reduce_mean(x, axis=3, keepdims=True),
        output_shape=avg_pool_output_shape
    )(input_feature)

    max_pool = layers.Lambda(
        lambda x: tf.reduce_max(x, axis=3, keepdims=True),
        output_shape=max_pool_output_shape
    )(input_feature)

    concat = layers.Concatenate(axis=3)([avg_pool, max_pool])

    cbam_feature = layers.Conv2D(filters=1,
                                kernel_size=kernel_size,
                                strides=1,
                                padding='same',
                                activation='sigmoid',
                                kernel_initializer='he_normal',
                                use_bias=False)(concat)

    return layers.Multiply()([input_feature, cbam_feature])

def cbam_block(input_feature, ratio=8, kernel_size=7):
    """CBAM block integrating both channel and spatial attention"""
    cbam_feature = channel_attention(input_feature, ratio)
    cbam_feature = spatial_attention(cbam_feature, kernel_size)
    return cbam_feature

#####################################################
#                                                   #
#              DEEP ATTENTION MECHANISM             #
#                                                   #
#####################################################

def deep_channel_attention(input_feature, ratio=8):
    """Deep channel attention module with more layers than standard CBAM"""
    channel = input_feature.shape[-1]

    # Deeper MLP network for enhanced channel relationships
    shared_layer_one = layers.Dense(channel // ratio,
                                   activation='relu',
                                   kernel_initializer='he_normal',
                                   use_bias=True,
                                   bias_initializer='zeros')
    shared_layer_two = layers.Dense(channel // ratio // 2,
                                   activation='relu',
                                   kernel_initializer='he_normal',
                                   use_bias=True,
                                   bias_initializer='zeros')
    shared_layer_three = layers.Dense(channel,
                                     kernel_initializer='he_normal',
                                     use_bias=True,
                                     bias_initializer='zeros')

    # Average pooling path
    avg_pool = layers.GlobalAveragePooling2D()(input_feature)
    avg_pool = layers.Reshape((1, 1, channel))(avg_pool)
    avg_pool = shared_layer_one(avg_pool)
    avg_pool = shared_layer_two(avg_pool)
    avg_pool = shared_layer_three(avg_pool)

    # Max pooling path
    max_pool = layers.GlobalMaxPooling2D()(input_feature)
    max_pool = layers.Reshape((1, 1, channel))(max_pool)
    max_pool = shared_layer_one(max_pool)
    max_pool = shared_layer_two(max_pool)
    max_pool = shared_layer_three(max_pool)

    # Attention weights
    da_feature = layers.Add()([avg_pool, max_pool])
    da_feature = layers.Activation('sigmoid')(da_feature)

    return layers.Multiply()([input_feature, da_feature])

def deep_spatial_attention(input_feature, kernel_size=7):
    """Deep spatial attention module with additional convolutional layer"""
    # Generate spatial descriptors
    avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=3, keepdims=True))(input_feature)
    max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=3, keepdims=True))(input_feature)
    concat = layers.Concatenate(axis=3)([avg_pool, max_pool])

    # Two-layer CNN for deep spatial attention
    da_feature = layers.Conv2D(filters=16,
                              kernel_size=kernel_size,
                              strides=1,
                              padding='same',
                              activation='relu',
                              kernel_initializer='he_normal',
                              use_bias=False)(concat)

    da_feature = layers.Conv2D(filters=1,
                              kernel_size=kernel_size,
                              strides=1,
                              padding='same',
                              activation='sigmoid',
                              kernel_initializer='he_normal',
                              use_bias=False)(da_feature)

    return layers.Multiply()([input_feature, da_feature])

def deep_attention_block(input_feature, ratio=8, kernel_size=7):
    """Deep Attention block integrating deep channel and spatial attention"""
    da_feature = deep_channel_attention(input_feature, ratio)
    da_feature = deep_spatial_attention(da_feature, kernel_size)
    return da_feature

# Data loading and preprocessing
class RiceDiseaseDataset:
    def __init__(self, config):
        self.config = config
        self.metadata = pd.read_csv(config['metadata_path'])
        self.class_names = self._get_classes()
        self.num_classes = len(self.class_names)

        # Map class names to indices
        self.class_to_idx = {cls: i for i, cls in enumerate(self.class_names)}

        print(f"Dataset initialized with {self.num_classes} classes: {self.class_names}")

    def _get_classes(self):
        """Get the list of classes from the preprocessed directory"""
        return sorted([d for d in os.listdir(self.config['preprocessed_data_dir'])
                      if os.path.isdir(os.path.join(self.config['preprocessed_data_dir'], d))])

    def load_data(self):
        """Load all images and labels from the preprocessed directory"""
        class_labels = []
        age_labels = []
        image_paths = []

        print("Loading dataset from preprocessed directory...")

        for class_name in self.class_names:
            class_dir = os.path.join(self.config['preprocessed_data_dir'], class_name)
            print(f"Processing class: {class_name}")

            # Get all image files in the class directory
            img_files = [f for f in os.listdir(class_dir)
                         if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]

            for img_file in tqdm(img_files, desc=f"Loading {class_name} images"):
                img_path = os.path.join(class_dir, img_file)

                # Find corresponding metadata for regression task (age)
                img_metadata = self.metadata[self.metadata['image_id'] == img_file]

                if not img_metadata.empty:
                    age = img_metadata['age'].values[0]
                else:
                    # If metadata is not found, use a default value or skip
                    print(f"Warning: No metadata found for {img_file}, using default age")
                    age = -1  # Mark as unknown

                # Add to our dataset
                image_paths.append(img_path)
                class_labels.append(self.class_to_idx[class_name])
                age_labels.append(age)

        print(f"Total images loaded: {len(image_paths)}")

        # Convert to numpy arrays
        class_labels = np.array(class_labels)
        age_labels = np.array(age_labels)

        return image_paths, class_labels, age_labels

    def split_data(self, image_paths, class_labels, age_labels):
        """Split the data into training, validation, and test sets"""
        # First split into train and temp
        train_paths, temp_paths, train_cls, temp_cls, train_age, temp_age = train_test_split(
            image_paths, class_labels, age_labels,
            test_size=(self.config['val_split'] + self.config['test_split']),
            random_state=self.config['random_state'],
            stratify=class_labels
        )

        # Then split temp into validation and test
        val_ratio = self.config['val_split'] / (self.config['val_split'] + self.config['test_split'])
        val_paths, test_paths, val_cls, test_cls, val_age, test_age = train_test_split(
            temp_paths, temp_cls, temp_age,
            test_size=(1 - val_ratio),
            random_state=self.config['random_state'],
            stratify=temp_cls
        )

        print(f"Data split: Train={len(train_paths)}, Validation={len(val_paths)}, Test={len(test_paths)}")

        return {
            'train': (train_paths, train_cls, train_age),
            'val': (val_paths, val_cls, val_age),
            'test': (test_paths, test_cls, test_age)
        }

# Data augmentation for rice disease images
def get_augmentation_layers():
    """Create (once) a reusable augmentation Sequential."""
    # -- make RandomBrightness optional for older TF versions
    brightness_layer = (
        layers.RandomBrightness(0.1)
        if hasattr(layers, "RandomBrightness")
        else layers.Lambda(
            lambda x: tf.image.random_brightness(x, 0.1),
            output_shape=lambda ishape: ishape
        )
    )

    return keras.Sequential(
        [
            layers.RandomRotation(0.20),
            layers.RandomTranslation(0.10, 0.10),
            layers.RandomZoom(0.10),
            layers.RandomContrast(0.20),
            brightness_layer,
        ],
        name="data_augmentation",
    )
# Create TensorFlow data generators using keras.utils.image_dataset_from_directory
def create_generators(dataset_splits, config):
    """Create optimized TensorFlow data generators for training, validation, and testing"""
    # Create temp directories for each split
    temp_base = tempfile.mkdtemp()
    temp_dirs = {
        'train': os.path.join(temp_base, 'train'),
        'val': os.path.join(temp_base, 'val'),
        'test': os.path.join(temp_base, 'test')
    }

    # Create class subdirectories in each split directory
    dataset = RiceDiseaseDataset(config)
    class_names = dataset.class_names

    for split_name, temp_dir in temp_dirs.items():
        for class_name in class_names:
            os.makedirs(os.path.join(temp_dir, class_name), exist_ok=True)

    # Copy or create symlinks to images in the split datasets
    for split_name, (paths, labels, _) in dataset_splits.items():
        for img_path, label in zip(paths, labels):
            class_name = class_names[label]
            # Create a symlink instead of copying to save space/time
            dest_path = os.path.join(temp_dirs[split_name], class_name, os.path.basename(img_path))
            try:
                os.symlink(os.path.abspath(img_path), dest_path)
            except (OSError, AttributeError):
                # Fallback to copy if symlink fails (e.g., on Windows)
                shutil.copy(img_path, dest_path)

    # Create augmentation layer
    augmentation = get_augmentation_layers()

    # Create datasets using keras.utils.image_dataset_from_directory
    train_ds = keras.utils.image_dataset_from_directory(
        directory=temp_dirs['train'],
        labels='inferred',
        label_mode='int',  # sparse categorical format
        batch_size=config['batch_size'],
        image_size=config['img_size'],
        shuffle=True,
        seed=config['random_state'],
        validation_split=None
    )

    # Apply augmentation to training data
    train_ds = train_ds.map(
        lambda x, y: (augmentation(x, training=True), y),
        num_parallel_calls=tf.data.AUTOTUNE
    )

    # Optimize performance
    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)

    val_ds = keras.utils.image_dataset_from_directory(
        directory=temp_dirs['val'],
        labels='inferred',
        label_mode='int',
        batch_size=config['batch_size'],
        image_size=config['img_size'],
        shuffle=False,
        seed=config['random_state']
    )
    val_ds = val_ds.prefetch(tf.data.AUTOTUNE)

    test_ds = keras.utils.image_dataset_from_directory(
        directory=temp_dirs['test'],
        labels='inferred',
        label_mode='int',
        batch_size=config['batch_size'],
        image_size=config['img_size'],
        shuffle=False
    )
    test_ds = test_ds.prefetch(tf.data.AUTOTUNE)

    return train_ds, val_ds, test_ds

################################################
#                                              #
#              MODEL ARCHITECTURE              #
#                                              #
################################################


def build_densenet201_with_cbam(num_classes, input_shape=(224, 224, 3)):
    """Build DenseNet201 model with CBAM attention"""
    base_model = DenseNet201(
        include_top=False,
        weights=None,
        input_shape=input_shape,
        # pooling=None
    )

    # Add CBAM attention to the output of the base model
    x = base_model.output
    x = cbam_block(x)

    # Add classification head
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.Dropout(0.3)(x)

    # Use float32 for the final layer for numeric stability
    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)

    model = keras.Model(inputs=base_model.input, outputs=outputs)
    return model

def build_inceptionresnetv2_with_cbam(num_classes, input_shape=(224, 224, 3)):
    """Build InceptionResNetV2 model with CBAM attention"""
    base_model = InceptionResNetV2(
        include_top=False,
        weights=None,
        input_shape=input_shape,
        # pooling=None
    )

    # Add CBAM attention to the output of the base model
    x = base_model.output
    x = cbam_block(x)

    # Add classification head
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.Dropout(0.3)(x)

    # Use float32 for the final layer for numeric stability
    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)

    model = keras.Model(inputs=base_model.input, outputs=outputs)
    return model

def build_xception_with_cbam(num_classes, input_shape=(224, 224, 3)):
    """Build Xception model with CBAM attention"""
    base_model = Xception(
        include_top=False,
        weights=None,
        input_shape=input_shape,
        # pooling=None
    )

    # Add CBAM attention to the output of the base model
    x = base_model.output
    x = cbam_block(x)

    # Add classification head
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.Dropout(0.3)(x)

    # Use float32 for the final layer for numeric stability
    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)

    model = keras.Model(inputs=base_model.input, outputs=outputs)
    return model

def build_inceptionv3_with_cbam(num_classes, input_shape=(224, 224, 3)):
    """Build InceptionV3 model with CBAM attention"""
    base_model = InceptionV3(
        include_top=False,
        weights=None,
        input_shape=input_shape
    )

    # Add CBAM attention to the output of the base model
    x = base_model.output
    x = cbam_block(x)

    # Add classification head
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.Dropout(0.3)(x)

    # Use float32 for the final layer for numeric stability
    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)

    model = keras.Model(inputs=base_model.input, outputs=outputs)
    return model

def build_vgg19_with_deep_attention(num_classes, input_shape=(224, 224, 3)):
    """Build VGG19 model with Deep Attention"""
    base_model = VGG19(
        include_top=False,
        weights=None,
        input_shape=input_shape
    )

    x = base_model.output
    x = deep_attention_block(x)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.Dropout(0.3)(x)
    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)

    model = keras.Model(inputs=base_model.input, outputs=outputs)
    return model

def build_resnet101v2_with_deep_attention(num_classes, input_shape=(224, 224, 3)):
    """Build ResNet101V2 model with Deep Attention"""
    base_model = ResNet101V2(
        include_top=False,
        weights=None,
        input_shape=input_shape
    )

    x = base_model.output
    x = deep_attention_block(x)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.Dropout(0.3)(x)
    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)

    model = keras.Model(inputs=base_model.input, outputs=outputs)
    return model

def build_custom_cnn_with_deep_attention(num_classes, input_shape=(224, 224, 3)):
    """Build Custom CNN model with Deep Attention"""
    # Fixed hyperparameters based on provided architecture
    activation = 'relu'
    dropout_rate = 0.3
    l2_reg = 1e-4
    num_filters = 64

    def act_layer(x):
        if activation == 'leaky_relu':
            return layers.LeakyReLU()(x)
        else:
            return layers.Activation(activation)(x)

    inputs = keras.Input(shape=input_shape)

    # First block
    x = layers.Conv2D(num_filters, (3,3), padding='same', use_bias=False,
                     kernel_regularizer=keras.regularizers.l2(l2_reg))(inputs)
    x = layers.BatchNormalization()(x)
    x = act_layer(x)
    x = layers.Conv2D(num_filters, (3,3), padding='same', use_bias=False,
                     kernel_regularizer=keras.regularizers.l2(l2_reg))(x)
    x = layers.BatchNormalization()(x)
    x = act_layer(x)
    x = deep_attention_block(x)
    x = layers.MaxPooling2D()(x)
    x = layers.Dropout(dropout_rate)(x)

    # Second block
    x = layers.Conv2D(num_filters*2, (3,3), padding='same', use_bias=False,
                     kernel_regularizer=keras.regularizers.l2(l2_reg))(x)
    x = layers.BatchNormalization()(x)
    x = act_layer(x)
    x = layers.Conv2D(num_filters*2, (3,3), padding='same', use_bias=False,
                     kernel_regularizer=keras.regularizers.l2(l2_reg))(x)
    x = layers.BatchNormalization()(x)
    x = act_layer(x)
    x = deep_attention_block(x)
    x = layers.MaxPooling2D()(x)
    x = layers.Dropout(dropout_rate)(x)

    # Third block
    x = layers.Conv2D(num_filters*4, (3,3), padding='same', use_bias=False,
                     kernel_regularizer=keras.regularizers.l2(l2_reg))(x)
    x = layers.BatchNormalization()(x)
    x = act_layer(x)
    x = layers.Conv2D(num_filters*4, (3,3), padding='same', use_bias=False,
                     kernel_regularizer=keras.regularizers.l2(l2_reg))(x)
    x = layers.BatchNormalization()(x)
    x = act_layer(x)
    x = deep_attention_block(x)
    x = layers.MaxPooling2D()(x)
    x = layers.Dropout(dropout_rate)(x)

    # Classification head
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(128, activation=activation,
                    kernel_regularizer=keras.regularizers.l2(l2_reg))(x)
    x = layers.Dropout(dropout_rate)(x)
    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)

    model = keras.Model(inputs, outputs)
    return model

class TqdmProgressCallback(Callback):
    def __init__(self, epochs):
        super().__init__()
        self.epochs = epochs
        self.progbar = None

    def on_train_begin(self, logs=None):
        self.progbar = tqdm(total=self.epochs, desc="Training", position=0)

    def on_epoch_end(self, epoch, logs=None):
        self.progbar.update(1)
        self.progbar.set_postfix({k: f"{v:.4f}" for k, v in logs.items()})

    def on_train_end(self, logs=None):
        self.progbar.close()

################################################
#                                              #
#                MODEL TRAINING                #
#                                              #
################################################

def train_classification_model(model, model_name, train_ds, val_ds, config):
    """Train a classification model"""
    # Compile the model
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=config['learning_rate']),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    # Set up callbacks
    checkpoint_path = os.path.join(config['output_dir'], 'models', f"{model_name}_best.keras")
    weights_path = os.path.join(config['output_dir'], 'models', f"{model_name}_best_weights.weights.h5")
    callbacks = [
        ModelCheckpoint(
            checkpoint_path,
            monitor='val_accuracy',
            save_best_only=True,
            mode='max',
            verbose=1
        ),
        # Add weights-only checkpoint
        ModelCheckpoint(
            weights_path,
            monitor='val_accuracy',
            save_best_only=True,
            save_weights_only=True,
            mode='max',
            verbose=1
        ),
        EarlyStopping(
            monitor='val_accuracy',
            patience=20,
            restore_best_weights=True,
            verbose=1
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=3,
            min_lr=1e-6,
            verbose=1
        ),
        TensorBoard(
            log_dir=os.path.join(config['output_dir'], 'logs', model_name),
            histogram_freq=1
        ),
        TqdmProgressCallback(epochs=config['epochs'])
    ]

    # Train the model
    print(f"Training {model_name} model...")
    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=config['epochs'],
        callbacks=callbacks,
        verbose=1
    )

    # Save the final model and weights
    model.save(os.path.join(config['output_dir'], 'models', f"{model_name}_final.keras"))
    model.save_weights(os.path.join(config['output_dir'], 'models', f"{model_name}_final_weights.weights.h5"))

    # Save training history
    history_path = os.path.join(config['output_dir'], 'metrics', f"{model_name}_history.json")
    with open(history_path, 'w') as f:
        hist_dict = history.history
        # Convert numpy arrays to lists for JSON serialization
        for key in hist_dict:
            hist_dict[key] = [float(x) for x in hist_dict[key]]
        json.dump(hist_dict, f, indent=4)

    return model, history

################################################
#                                              #
#              MODEL EVALUATION                #
#                                              #
################################################


def evaluate_classification_model(model, model_name, test_ds, class_names, config):
    """Evaluate a classification model"""
    print(f"Evaluating {model_name} model...")

    # Use TensorFlow's built-in methods to collect predictions efficiently
    y_true = []
    y_pred = []
    y_prob = []

    # Process in manageable chunks with timeout protection
    for images, labels in tqdm(test_ds, desc="Evaluating", dynamic_ncols=True, leave=True, position=0):
        try:
            with tf.keras.utils.custom_object_scope({'timeout': 30}):
                batch_pred = model.predict(images, verbose=0, batch_size=None)
            y_prob.extend(batch_pred)
            y_pred.extend(np.argmax(batch_pred, axis=1))
            y_true.extend(labels.numpy())
        except Exception as e:
            print(f"Warning: Prediction timed out or failed: {e}")
            continue

    # Convert to numpy arrays for easier handling
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    y_prob = np.array(y_prob)

    # Find classes that actually appear in the data
    present_in_true = sorted(np.unique(y_true))
    present_in_pred = sorted(np.unique(y_pred))
    present_classes = sorted(set(present_in_true).union(set(present_in_pred)))

    print(f"Classes present in true labels: {present_in_true}")
    print(f"Classes present in predictions: {present_in_pred}")
    print(f"Total classes present: {present_classes}")
    print(f"Number of classes in class_names: {len(class_names)}")

    # metrics ---------------------------------------------------------------
    accuracy = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, average="weighted", zero_division=0)

    # ROC-AUC - skip if only one class is present
    roc_auc = None
    if len(present_in_true) > 1:
        y_true_onehot = tf.keras.utils.to_categorical(y_true, num_classes=len(class_names))
        try:
            # Only calculate ROC-AUC if we have multiple classes
            roc_auc = roc_auc_score(
                y_true_onehot, y_prob, average="weighted", multi_class="ovr"
            )
        except ValueError as e:
            print(f"Warning: Could not calculate ROC-AUC: {e}")
    else:
        print("Warning: Only one class present in true labels. ROC-AUC score is not defined.")

    # Generate classification report
    present_class_names = [class_names[i] if i < len(class_names) else f"Unknown-{i}" for i in present_classes]

    # Use zero_division=0 to suppress the warnings
    class_report = classification_report(
        y_true, y_pred,
        labels=present_classes,
        target_names=present_class_names,
        output_dict=True,
        zero_division=0  # This fixes the "Precision is ill-defined" warnings
    )

    # Generate confusion matrix for present classes
    cm = confusion_matrix(y_true, y_pred, labels=present_classes)

    # Save metrics
    metrics = {
        'accuracy': float(accuracy),
        'f1_score': float(f1),
        'roc_auc_score': float(roc_auc) if roc_auc is not None else None,
        'classification_report': class_report
    }

    metrics_path = os.path.join(config['output_dir'], 'metrics', f"{model_name}_metrics.json")
    with open(metrics_path, 'w') as f:
        json.dump(metrics, f, indent=4)

    # Plot and save confusion matrix
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
               xticklabels=present_class_names,
               yticklabels=present_class_names)
    plt.title(f'Confusion Matrix - {model_name}')
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()
    plt.savefig(os.path.join(config['output_dir'], 'plots', f"{model_name}_confusion_matrix.png"))
    plt.close()

    # Plot ROC curves only if we have multiple classes and ROC-AUC is defined
    if roc_auc is not None and len(present_in_true) > 1:
        plt.figure(figsize=(10, 8))
        for i in present_in_true:
            if i < len(class_names):
                try:
                    fpr, tpr, _ = roc_curve(y_true_onehot[:, i], y_prob[:, i])
                    plt.plot(fpr, tpr, lw=2, label=f"{class_names[i]} (AUC={auc(fpr,tpr):.2f})")
                except Exception as e:
                    print(f"Warning: Could not plot ROC curve for class {class_names[i]}: {e}")

        plt.plot([0, 1], [0, 1], "k--", lw=2)
        plt.xlim([0, 1])
        plt.ylim([0, 1.05])
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.title(f"ROC curves â€“ {model_name}")
        plt.legend(loc="lower right")
        plt.savefig(os.path.join(config["output_dir"], "plots", f"{model_name}_roc.png"))
        plt.close()
    else:
        print("Skipping ROC curve plot - insufficient class representation")

    # Plot and save training history
    history_path = os.path.join(config['output_dir'], 'metrics', f"{model_name}_history.json")
    with open(history_path, 'r') as f:
        history = json.load(f)

    plt.figure(figsize=(12, 5))

    # Plot accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history['accuracy'], label='Training Accuracy')
    plt.plot(history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    # Plot loss
    plt.subplot(1, 2, 2)
    plt.plot(history['loss'], label='Training Loss')
    plt.plot(history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.savefig(os.path.join(config['output_dir'], 'plots', f"{model_name}_training_history.png"))
    plt.close()

    print(f"Metrics saved for {model_name}:")
    print(f"  Accuracy: {accuracy:.4f}")
    print(f"  F1 Score: {f1:.4f}")
    if roc_auc is not None:
        print(f"  ROC-AUC Score: {roc_auc:.4f}")
    else:
        print("  ROC-AUC Score: Not calculated (insufficient class representation)")

    return metrics

# For age classification (modifying the regression task)
def convert_age_to_categories(ages):
    """Convert continuous age values to categorical classes"""
    # Find unique ages and create bins
    unique_ages = np.unique(ages)
    print(f"Unique age values: {unique_ages}")

    # Create age categories (you can adjust these based on your domain knowledge)
    age_to_category = {}
    categories = sorted(unique_ages)
    for i, age in enumerate(categories):
        age_to_category[age] = i

    return categories, age_to_category

# Main execution functions
################################################
#                                              #
#        Task 1 - Disease Classification       #
#                                              #
################################################

def run_classification_task():
    """Run the multi-class classification task"""
    print("\n" + "="*50)
    print("Starting Multi-Class Classification Task")
    print("="*50)

    # Initialize dataset
    rice_dataset = RiceDiseaseDataset(CONFIG)

    # Load data
    image_paths, class_labels, age_labels = rice_dataset.load_data()

    # Print class distribution
    unique_classes, class_counts = np.unique(class_labels, return_counts=True)
    print("\nClass distribution in full dataset:")
    for cls_idx, count in zip(unique_classes, class_counts):
        print(f"  Class {rice_dataset.class_names[cls_idx]}: {count} images")

    # Split data
    dataset_splits = rice_dataset.split_data(image_paths, class_labels, age_labels)

    # Check class distribution in train/val/test sets
    print("\nClass distribution in splits:")
    for split_name, (_, split_labels, _) in dataset_splits.items():
        unique_classes, class_counts = np.unique(split_labels, return_counts=True)
        print(f"  {split_name} split:")
        for cls_idx, count in zip(unique_classes, class_counts):
            print(f"    Class {rice_dataset.class_names[cls_idx]}: {count} images")

    # Create data generators
    train_ds, val_ds, test_ds = create_generators(dataset_splits, CONFIG)

    # Dictionary of model building functions
    model_builders = {
        'xception': build_xception_with_cbam,
        'inceptionresnetv2': build_inceptionresnetv2_with_cbam,
        'densenet201': build_densenet201_with_cbam,
        'inceptionv3': build_inceptionv3_with_cbam
    }

    # Train and evaluate each model
    model_metrics = {}

    for model_name, model_builder in model_builders.items():
        print(f"\nProcessing {model_name} model...")

        # Build model
        model = model_builder(rice_dataset.num_classes, input_shape=(*CONFIG['img_size'], 3))

        # Train model
        model, history = train_classification_model(model, model_name, train_ds, val_ds, CONFIG)

        # Check model predictions before evaluation
        print("\nChecking model predictions on test set:")
        for images, labels in test_ds.take(1):  # Just check one batch
            pred = model.predict(images)
            pred_classes = np.argmax(pred, axis=1)
            print(f"  Predicted class distribution in sample batch:")
            unique_preds, pred_counts = np.unique(pred_classes, return_counts=True)
            for cls_idx, count in zip(unique_preds, pred_counts):
                if cls_idx < len(rice_dataset.class_names):
                    print(f"    Class {rice_dataset.class_names[cls_idx]}: {count} predictions")
                else:
                    print(f"    Class {cls_idx} (invalid): {count} predictions")

            print("  First 5 prediction probabilities:")
            for i in range(min(5, len(pred))):
                print(f"    Image {i}: {pred[i]}")

            print(f"  Ground truth: {labels[:5]}")
            print(f"  Predictions: {pred_classes[:5]}")

        # Evaluate model
        metrics = evaluate_classification_model(model, model_name, test_ds, rice_dataset.class_names, CONFIG)
        model_metrics[model_name] = metrics

        # Clear the model from memory
        keras.backend.clear_session()

    # Compare models and save results
    comparison = {
        'accuracy': {name: metrics['accuracy'] for name, metrics in model_metrics.items()},
        'f1_score': {name: metrics['f1_score'] for name, metrics in model_metrics.items()},
        'roc_auc_score': {name: metrics['roc_auc_score'] for name, metrics in model_metrics.items()}
    }

    comparison_path = os.path.join(CONFIG['output_dir'], 'metrics', "classification_comparison.json")
    with open(comparison_path, 'w') as f:
        json.dump(comparison, f, indent=4)

    # Plot comparison
    plt.figure(figsize=(15, 6))
    metrics_list = ['accuracy', 'f1_score', 'roc_auc_score']

    for i, metric in enumerate(metrics_list):
        plt.subplot(1, 3, i+1)
        model_names = list(comparison[metric].keys())
        values = list(comparison[metric].values())

        bars = plt.bar(model_names, values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])

        # Add value labels on bars
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{height:.4f}', ha='center', va='bottom', rotation=0)

        plt.title(f'{metric.replace("_", " ").title()}')
        plt.ylim(0, 1.05)
        plt.xticks(rotation=45)

    plt.tight_layout()
    plt.savefig(os.path.join(CONFIG['output_dir'], 'plots', "classification_comparison.png"))
    plt.close()

    print("\nClassification task completed successfully!")
    print(f"Results saved to {CONFIG['output_dir']}")

################################################
#                                              #
#        Task 2 - Variety Classification       #
#                                              #
################################################

def run_variety_classification_task():
    """Run the variety classification task using rice plant varieties"""
    print("\n" + "="*50)
    print("Starting Variety Classification Task")
    print("="*50)

    # Initialize dataset
    rice_dataset = RiceDiseaseDataset(CONFIG)

    # Load data
    image_paths, class_labels, _ = rice_dataset.load_data()

    # Load metadata to get variety information
    metadata = pd.read_csv(CONFIG['metadata_path'])

    # Extract variety information
    variety_labels = []
    valid_indices = []

    for i, img_path in enumerate(image_paths):
        img_filename = os.path.basename(img_path)
        img_metadata = metadata[metadata['image_id'] == img_filename]

        if not img_metadata.empty and 'variety' in img_metadata.columns:
            variety = img_metadata['variety'].values[0]
            if pd.notna(variety) and variety.strip():
                variety_labels.append(variety)
                valid_indices.append(i)

    # Filter data to only include entries with valid variety information
    filtered_image_paths = [image_paths[i] for i in valid_indices]
    filtered_class_labels = class_labels[valid_indices]

    variety_labels = np.array(variety_labels)

    # Convert variety strings to numerical categories
    unique_varieties = sorted(set(variety_labels))
    variety_to_idx = {variety: idx for idx, variety in enumerate(unique_varieties)}
    numerical_variety_labels = np.array([variety_to_idx[variety] for variety in variety_labels])

    print(f"Found {len(unique_varieties)} unique rice varieties: {unique_varieties}")
    print(f"Using {len(filtered_image_paths)} images with valid variety labels")

    # Create dataset splits for variety classification
    dataset_splits = rice_dataset.split_data(
        filtered_image_paths,
        filtered_class_labels,
        numerical_variety_labels
    )

    # Create temp directories for each split
    temp_base = tempfile.mkdtemp()
    temp_dirs = {
        'train': os.path.join(temp_base, 'train'),
        'val': os.path.join(temp_base, 'val'),
        'test': os.path.join(temp_base, 'test')
    }

    # Create variety subdirectories
    for split_name, temp_dir in temp_dirs.items():
        for variety in unique_varieties:
            os.makedirs(os.path.join(temp_dir, variety), exist_ok=True)

    # Distribute images to variety folders
    for split_name, (paths, _, varieties) in dataset_splits.items():
        for img_path, variety_idx in zip(paths, varieties):
            variety = unique_varieties[variety_idx]
            dest_path = os.path.join(temp_dirs[split_name], variety, os.path.basename(img_path))
            try:
                os.symlink(os.path.abspath(img_path), dest_path)
            except (OSError, AttributeError):
                shutil.copy(img_path, dest_path)

    # Create datasets
    train_ds = keras.utils.image_dataset_from_directory(
        directory=temp_dirs['train'],
        labels='inferred',
        label_mode='int',
        batch_size=CONFIG['batch_size'],
        image_size=CONFIG['img_size'],
        shuffle=True,
        seed=CONFIG['random_state']
    )

    # Apply augmentation
    augmentation = get_augmentation_layers()
    train_ds = train_ds.map(
        lambda x, y: (augmentation(x, training=True), y),
        num_parallel_calls=tf.data.AUTOTUNE
    )
    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)

    val_ds = keras.utils.image_dataset_from_directory(
        directory=temp_dirs['val'],
        labels='inferred',
        label_mode='int',
        batch_size=CONFIG['batch_size'],
        image_size=CONFIG['img_size'],
        shuffle=False
    )
    val_ds = val_ds.prefetch(tf.data.AUTOTUNE)

    test_ds = keras.utils.image_dataset_from_directory(
        directory=temp_dirs['test'],
        labels='inferred',
        label_mode='int',
        batch_size=CONFIG['batch_size'],
        image_size=CONFIG['img_size'],
        shuffle=False
    )
    test_ds = test_ds.prefetch(tf.data.AUTOTUNE)

    # Model builders with Deep Attention
    model_builders = {
        'vgg19': build_vgg19_with_deep_attention,
        'resnet101v2': build_resnet101v2_with_deep_attention,
        'custom_cnn': build_custom_cnn_with_deep_attention
    }

    # Train and evaluate models
    model_metrics = {}

    for model_name, model_builder in model_builders.items():
        print(f"\nProcessing {model_name} model for variety classification...")

        # Build model
        model = model_builder(len(unique_varieties), input_shape=(*CONFIG['img_size'], 3))

        # Train model
        model, history = train_classification_model(
            model,
            f"{model_name}_variety",
            train_ds,
            val_ds,
            CONFIG
        )

        # Evaluate model
        metrics = evaluate_classification_model(
            model,
            f"{model_name}_variety",
            test_ds,
            unique_varieties,
            CONFIG
        )
        model_metrics[model_name] = metrics

        # Clear memory
        keras.backend.clear_session()

    # Compare models
    comparison = {
        'accuracy': {name: metrics['accuracy'] for name, metrics in model_metrics.items()},
        'f1_score': {name: metrics['f1_score'] for name, metrics in model_metrics.items()},
        'roc_auc_score': {name: metrics['roc_auc_score'] for name, metrics in model_metrics.items()
                         if metrics['roc_auc_score'] is not None}
    }

    # Save comparison
    comparison_path = os.path.join(CONFIG['output_dir'], 'metrics', "variety_classification_comparison.json")
    with open(comparison_path, 'w') as f:
        json.dump(comparison, f, indent=4)

    # Plot comparison
    plt.figure(figsize=(15, 6))
    metrics_list = ['accuracy', 'f1_score', 'roc_auc_score']

    for i, metric in enumerate(metrics_list):
        if metric in comparison:
            plt.subplot(1, 3, i+1)
            model_names = list(comparison[metric].keys())
            values = list(comparison[metric].values())

            bars = plt.bar(model_names, values, color=['#1f77b4', '#ff7f0e', '#2ca02c'])

            # Add value labels
            for bar in bars:
                height = bar.get_height()
                plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                        f'{height:.4f}', ha='center', va='bottom', rotation=0)

            plt.title(f'{metric.replace("_", " ").title()}')
            plt.ylim(0, 1.05)
            plt.xticks(rotation=45)

    plt.tight_layout()
    plt.savefig(os.path.join(CONFIG['output_dir'], 'plots', "variety_classification_comparison.png"))
    plt.close()

    print("\nVariety classification task completed successfully!")
    print(f"Results saved to {CONFIG['output_dir']}")

################################################
#                                              #
#        Task 3 - Age Classification           #
#                                              #
################################################


def run_age_classification_task():
    """Run the age classification task"""
    print("\n" + "="*50)
    print("Starting Age Classification Task")
    print("="*50)

    # Initialize dataset
    rice_dataset = RiceDiseaseDataset(CONFIG)

    # Load data
    image_paths, class_labels, age_labels = rice_dataset.load_data()

    # Filter out any data points with missing age labels
    valid_indices = np.where(age_labels >= 0)[0]

    if len(valid_indices) < len(age_labels):
        print(f"Warning: Filtering out {len(age_labels) - len(valid_indices)} data points with missing age labels")
        image_paths = [image_paths[i] for i in valid_indices]
        class_labels = class_labels[valid_indices]
        age_labels = age_labels[valid_indices]

    # Convert ages to categories
    age_categories, age_to_category = convert_age_to_categories(age_labels)
    num_age_classes = len(age_categories)
    print(f"Created {num_age_classes} age categories: {age_categories}")

    # Convert continuous ages to categorical
    categorical_age_labels = np.array([age_to_category[age] for age in age_labels])

    # Create new dataset splits for age classification
    dataset_splits_age = rice_dataset.split_data(image_paths, class_labels, categorical_age_labels)

    # Create temp directories for each split
    temp_base = tempfile.mkdtemp()
    temp_dirs = {
        'train': os.path.join(temp_base, 'train'),
        'val': os.path.join(temp_base, 'val'),
        'test': os.path.join(temp_base, 'test')
    }

    # Create age category subdirectories
    for split_name, temp_dir in temp_dirs.items():
        for age_class in range(num_age_classes):
            # Use the actual category name/range for folder names
            age_folder = str(age_categories[age_class])
            os.makedirs(os.path.join(temp_dir, age_folder), exist_ok=True)

    # Distribute images to age category folders
    for split_name, (paths, _, ages) in dataset_splits_age.items():
        for img_path, age_class in zip(paths, ages):
            age_folder = str(age_categories[age_class])
            # Create a symlink instead of copying to save space/time
            dest_path = os.path.join(temp_dirs[split_name], age_folder, os.path.basename(img_path))
            try:
                os.symlink(os.path.abspath(img_path), dest_path)
            except (OSError, AttributeError):
                # Fallback to copy if symlink fails (e.g., on Windows)
                shutil.copy(img_path, dest_path)

    # Create datasets using keras.utils.image_dataset_from_directory
    train_ds = keras.utils.image_dataset_from_directory(
        directory=temp_dirs['train'],
        labels='inferred',
        label_mode='int',
        batch_size=CONFIG['batch_size'],
        image_size=CONFIG['img_size'],
        shuffle=True,
        seed=CONFIG['random_state']
    )

    # Apply augmentation to training data
    augmentation = get_augmentation_layers()
    train_ds = train_ds.map(
        lambda x, y: (augmentation(x, training=True), y),
        num_parallel_calls=tf.data.AUTOTUNE
    )
    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)

    val_ds = keras.utils.image_dataset_from_directory(
        directory=temp_dirs['val'],
        labels='inferred',
        label_mode='int',
        batch_size=CONFIG['batch_size'],
        image_size=CONFIG['img_size'],
        shuffle=False
    )
    val_ds = val_ds.prefetch(tf.data.AUTOTUNE)

    test_ds = keras.utils.image_dataset_from_directory(
        directory=temp_dirs['test'],
        labels='inferred',
        label_mode='int',
        batch_size=CONFIG['batch_size'],
        image_size=CONFIG['img_size'],
        shuffle=False
    )
    test_ds = test_ds.prefetch(tf.data.AUTOTUNE)

    # Dictionary of model building functions - reuse the same ones as for disease classification
    model_builders = {
        # 'xception': build_xception_with_cbam,
        'inceptionresnetv2': build_inceptionresnetv2_with_cbam,
        'densenet201': build_densenet201_with_cbam,
        'inceptionv3': build_inceptionv3_with_cbam
    }

    # Train and evaluate each model for age classification
    model_metrics = {}

    for model_name, model_builder in model_builders.items():
        print(f"\nProcessing {model_name} model for age classification...")

        # Build model with age classes
        model = model_builder(num_age_classes, input_shape=(*CONFIG['img_size'], 3))

        # Train model
        model, history = train_classification_model(
            model,
            f"{model_name}_age",
            train_ds,
            val_ds,
            CONFIG
        )

        # Evaluate model
        metrics = evaluate_classification_model(
            model,
            f"{model_name}_age",
            test_ds,
            [str(c) for c in age_categories],  # Convert age categories to strings for display
            CONFIG
        )
        model_metrics[model_name] = metrics

        # Clear the model from memory
        keras.backend.clear_session()

    # Compare models and save results
    comparison = {
        'accuracy': {name: metrics['accuracy'] for name, metrics in model_metrics.items()},
        'f1_score': {name: metrics['f1_score'] for name, metrics in model_metrics.items()},
        'roc_auc_score': {name: metrics['roc_auc_score'] for name, metrics in model_metrics.items() if metrics['roc_auc_score'] is not None}
    }

    comparison_path = os.path.join(CONFIG['output_dir'], 'metrics', "age_classification_comparison.json")
    with open(comparison_path, 'w') as f:
        json.dump(comparison, f, indent=4)

    # Plot comparison - same as for disease classification
    plt.figure(figsize=(15, 6))
    metrics_list = ['accuracy', 'f1_score', 'roc_auc_score']

    for i, metric in enumerate(metrics_list):
        plt.subplot(1, 3, i+1)
        model_names = list(comparison[metric].keys())
        values = list(comparison[metric].values())

        bars = plt.bar(model_names, values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])

        # Add value labels on bars
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{height:.4f}', ha='center', va='bottom', rotation=0)

        plt.title(f'{metric.replace("_", " ").title()}')
        plt.ylim(0, 1.05)
        plt.xticks(rotation=45)

    plt.tight_layout()
    plt.savefig(os.path.join(CONFIG['output_dir'], 'plots', "age_classification_comparison.png"))
    plt.close()

    print("\nAge classification task completed successfully!")
    print(f"Results saved to {CONFIG['output_dir']}")

################################################
#                                              #
#                 MODEL LOADING                #
#                                              #
################################################

def load_model_with_weights(model_name, num_classes, config):
    """Recreate model architecture and load weights"""
    # Create the model architecture based on name
    if 'xception' in model_name.lower():
        model = build_xception_with_cbam(num_classes, input_shape=(*config['img_size'], 3))
    elif 'inceptionresnetv2' in model_name.lower():
        model = build_inceptionresnetv2_with_cbam(num_classes, input_shape=(*config['img_size'], 3))
    elif 'densenet201' in model_name.lower():
        model = build_densenet201_with_cbam(num_classes, input_shape=(*config['img_size'], 3))
    elif 'inceptionv3' in model_name.lower():
        model = build_inceptionv3_with_cbam(num_classes, input_shape=(*config['img_size'], 3))
    elif 'vgg19' in model_name.lower():
        model = build_vgg19_with_deep_attention(num_classes, input_shape=(*config['img_size'], 3))
    elif 'resnet101v2' in model_name.lower():
        model = build_resnet101v2_with_deep_attention(num_classes, input_shape=(*config['img_size'], 3))
    elif 'custom_cnn' in model_name.lower():
        model = build_custom_cnn_with_deep_attention(num_classes, input_shape=(*config['img_size'], 3))
    else:
        raise ValueError(f"Unknown model architecture: {model_name}")

    # Load weights
    try:
        weights_path = os.path.join('models', f"{model_name}_best_weights.weights.h5")
        model.load_weights(weights_path)
    except:
        raise FileNotFoundError(f"No weights found for {model_name}")

    # Compile the model
    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(
        initial_learning_rate=config['learning_rate'],
        decay_steps=config['steps_per_epoch'],
        alpha=0.01
    )

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

################################################
#                                              #
#              OUTPUT PREDICTION               #
#                                              #
################################################

def predict_test_folder(test_dir, config, output_csv="predictions.csv"):
    """Predict on all images in a test folder and save results in CSV format"""
    # Get best models from metrics
    metrics_dir = os.path.join(config['output_dir'], 'metrics')

    # Find best disease model
    disease_models = []
    for model_name in ['xception', 'inceptionresnetv2', 'densenet201', 'inceptionv3']:
        metrics_path = os.path.join(metrics_dir, f"{model_name}_metrics.json")
        if os.path.exists(metrics_path):
            with open(metrics_path, 'r') as f:
                metrics = json.load(f)
                disease_models.append({
                    'name': model_name,
                    'accuracy': metrics['accuracy']
                })
    best_disease_model = sorted(disease_models, key=lambda x: x['accuracy'], reverse=True)[0]['name']

    # Find best variety model
    variety_models = []
    for model_name in ['vgg19_variety', 'resnet101v2_variety', 'custom_cnn_variety']:
        metrics_path = os.path.join(metrics_dir, f"{model_name}_metrics.json")
        if os.path.exists(metrics_path):
            with open(metrics_path, 'r') as f:
                metrics = json.load(f)
                variety_models.append({
                    'name': model_name,
                    'accuracy': metrics['accuracy']
                })
    best_variety_model = sorted(variety_models, key=lambda x: x['accuracy'], reverse=True)[0]['name'] if variety_models else None

    # Find best age model
    age_models = []
    for model_name in ['xception_age', 'inceptionresnetv2_age', 'densenet201_age', 'inceptionv3_age']:
        metrics_path = os.path.join(metrics_dir, f"{model_name}_metrics.json")
        if os.path.exists(metrics_path):
            with open(metrics_path, 'r') as f:
                metrics = json.load(f)
                age_models.append({
                    'name': model_name,
                    'accuracy': metrics['accuracy']
                })
    best_age_model = sorted(age_models, key=lambda x: x['accuracy'], reverse=True)[0]['name'] if age_models else None

    # Get all image paths in test directory (non-shuffled)
    image_paths = []
    for root, _, files in os.walk(test_dir):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                image_paths.append(os.path.join(root, file))

    print(f"Found {len(image_paths)} images in test directory")
    print("Starting predictions...")

    # Process images in original order
    results = []
    for img_path in tqdm(image_paths, desc="Processing images"):
        try:
            pred = predict_single_image(
                image_path=img_path,
                config=config,
                disease_model_name=best_disease_model,
                variety_model_name=best_variety_model,
                age_model_name=best_age_model
            )
            # Clean image_id by removing extension
            image_id = os.path.splitext(os.path.basename(img_path))[0]
            results.append({
                'image_id': image_id,
                'label': pred['label'],
                'variety': pred['variety'],
                'age': pred['age']
            })
        except Exception as e:
            print(f"Error processing {img_path}: {str(e)}")
            results.append({
                'image_id': os.path.basename(img_path),
                'label': 'error',
                'variety': 'error',
                'age': 'error'
            })

    # Create DataFrame and save CSV
    df = pd.DataFrame(results)

    # Ensure correct column order
    df = df[['image_id', 'label', 'variety', 'age']]

    # Save results
    output_path = os.path.join(config['output_dir'], 'predictions', output_csv)
    df.to_csv(output_path, index=False)
    print(f"\nPredictions saved to: {output_path}")

    return df

def create_fast_generator(data_dir, config):
    """Create optimized generator without temp files/shuffling"""
    return keras.utils.image_dataset_from_directory(
        directory=data_dir,
        labels=None,
        batch_size=config['batch_size'],
        image_size=config['img_size'],
        shuffle=False,
        seed=None
    ).prefetch(tf.data.AUTOTUNE)

def demonstrate_model_predictions():
    """Optimized prediction with direct directory loading"""
    print("\n" + "="*50)
    print("Running Fast Model Predictions")
    print("="*50)

    # Initialize components
    rice_dataset = RiceDiseaseDataset(CONFIG)
    metadata = pd.read_csv(CONFIG['metadata_path'])

    # Get class names
    disease_classes = rice_dataset.class_names
    variety_classes = sorted(metadata['variety'].dropna().unique())
    age_categories = sorted(metadata['age'].dropna().unique())

    # Find best models (from previous implementation)
    best_models = {
        'disease': 'inceptionresnetv2',  # Replace with your best model
        'variety': 'custom_cnn_variety',
        'age': 'xception_age'
    }

    # Load models once
    disease_model = load_model_with_weights(best_models['disease'], len(disease_classes), CONFIG)
    variety_model = load_model_with_weights(best_models['variety'], len(variety_classes), CONFIG)
    age_model = load_model_with_weights(best_models['age'], len(age_categories), CONFIG)

    # Create fast generator
    test_ds = create_fast_generator(CONFIG['predict_dataset_dir'], CONFIG)

    # Get original file paths in order
    file_paths = []
    for root, _, files in os.walk(CONFIG['predict_dataset_dir']):
        for file in sorted(files):
            if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                file_paths.append(os.path.join(root, file))

    # Batch predictions
    results = []
    batch_num = 0

    for batch in tqdm(test_ds, desc="Processing batches"):
        # Get predictions
        disease_preds = disease_model.predict(batch, verbose=0)
        variety_preds = variety_model.predict(batch, verbose=0)
        age_preds = age_model.predict(batch, verbose=0)

        # Process batch results
        batch_size = batch.shape[0]
        start_idx = batch_num * CONFIG['batch_size']
        end_idx = start_idx + batch_size

        for i in range(batch_size):
            if start_idx + i >= len(file_paths):
                break

            img_path = file_paths[start_idx + i]
            image_id = os.path.splitext(os.path.basename(img_path))[0]

            results.append({
                'image_id': image_id,
                'label': disease_classes[np.argmax(disease_preds[i])],
                'variety': variety_classes[np.argmax(variety_preds[i])],
                'age': int(age_categories[np.argmax(age_preds[i])])
            })

        batch_num += 1

    # Create and save DataFrame
    df = pd.DataFrame(results)
    df = df[['image_id', 'label', 'variety', 'age']]

    output_path = os.path.join(CONFIG['output_dir'], 'predictions', 'fast_predictions.csv')
    df.to_csv(output_path, index=False)

    print(f"\nPredictions complete! Saved {len(df)} records to {output_path}")
    return df
    return predictions_df

def predict_single_image(image_path, config, disease_model_name, variety_model_name=None, age_model_name=None):
    """Make predictions on a single image across all tasks"""
    print(f"\nPredicting for image: {os.path.basename(image_path)}")

    # Initialize dataset to get class names
    metadata = pd.read_csv(config['metadata_path'])
    disease_labels = metadata['label'].dropna().unique()
    disease_class_names = sorted(disease_labels)

    # Load metadata for variety class names
    variety_labels = metadata['variety'].dropna().unique()
    variety_class_names = sorted(variety_labels)

    # Load age categories
    age_labels = metadata['age'].dropna().unique()
    age_labels = np.array(age_labels, dtype=np.int32)
    age_labels.sort()

    # Create temporary directory for single image prediction
    temp_dir = tempfile.mkdtemp()
    os.makedirs(os.path.join(temp_dir, 'single_image'), exist_ok=True)
    temp_image_path = os.path.join(temp_dir, 'single_image', os.path.basename(image_path))
    shutil.copy(image_path, temp_image_path)

    # Create dataset
    single_ds = keras.utils.image_dataset_from_directory(
        directory=os.path.join(temp_dir, 'single_image'),
        labels=None,
        batch_size=config['batch_size'],
        image_size=config['img_size'],
        shuffle=False
    )

    # Initialize results dictionary
    results = {
        'image_id': os.path.basename(image_path),
        'image_path': image_path,
        'label': '',
        'variety': '',
        'age': '',
        'top3_disease': [],
        'top3_variety': [],
        'top3_age': []
    }

    try:
        # Disease prediction
        disease_model = load_model_with_weights(disease_model_name, len(disease_class_names), config)
        disease_pred = disease_model.predict(single_ds)
        disease_class_idx = np.argmax(disease_pred[0])
        results['label'] = disease_class_names[disease_class_idx]
        top3_indices = np.argsort(disease_pred[0])[-3:][::-1]
        top3_probs = disease_pred[0][top3_indices] * 100
        results['top3_disease'] = [
            {'class': disease_class_names[idx], 'probability': round(prob, 2)} 
            for idx, prob in zip(top3_indices, top3_probs)
        ]
        print(f"Disease prediction: {results['label']}")
        print(f"Top 3 disease predictions: {results['top3_disease']}")
    except Exception as e:
        print(f"Error in disease prediction: {str(e)}")

    try:
        # Variety prediction
        if variety_model_name:
            variety_model = load_model_with_weights(variety_model_name, len(variety_class_names), config)
            variety_pred = variety_model.predict(single_ds)
            variety_class_idx = np.argmax(variety_pred[0])
            results['variety'] = variety_class_names[variety_class_idx]

            # Get top 3 predictions and their probabilities
            top3_indices = np.argsort(variety_pred[0])[-3:][::-1]
            top3_probs = variety_pred[0][top3_indices] * 100

            results['top3_variety'] = [
                {'class': variety_class_names[idx], 'probability': round(prob, 2)} 
                for idx, prob in zip(top3_indices, top3_probs)
            ]

            print(f"Variety prediction: {results['variety']}")
            print(f"Top 3 variety predictions: {results['top3_variety']}")
    except Exception as e:
        print(f"Error in variety prediction: {str(e)}")

    try:
        # Age prediction with conversion back to original value
        if age_model_name:
            age_model = load_model_with_weights(age_model_name, len(age_labels), config)
            age_pred = age_model.predict(single_ds)
            age_class_idx = np.argmax(age_pred[0])
            results['age'] = int(age_labels[age_class_idx])

            # Get top 3 predictions and their probabilities
            top3_indices = np.argsort(age_pred[0])[-3:][::-1]
            top3_probs = age_pred[0][top3_indices] * 100
            results['top3_age'] = [
                {'value': int(age_labels[idx]), 'probability': round(prob, 2)} 
                for idx, prob in zip(top3_indices, top3_probs)
            ]

            print(f"Age prediction: {results['age']}")
            print(f"Top 3 age predictions: {results['top3_age']}")
    except Exception as e:
        print(f"Error in age prediction: {str(e)}")

    # Clean up temporary directory
    shutil.rmtree(temp_dir)

    return results

# Create timestamp for logging
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
print(f"Starting training pipeline at {timestamp}")

# Record execution time
start_time = time.time()

try:
    # # Run classification task
    # run_classification_task()

    # Run age classification task
    # run_age_classification_task()

    # # Run variety classification task
    # run_variety_classification_task()

    # Demonstrate model loading and predictions
    # demonstrate_model_predictions()

    # Calculate and print total execution time
    execution_time = time.time() - start_time
    hours, remainder = divmod(execution_time, 3600)
    minutes, seconds = divmod(remainder, 60)

    print("\n" + "="*50)
    print(f"Pipeline completed successfully in {int(hours)}h {int(minutes)}m {int(seconds)}s")
    print("="*50)

except Exception as e:
    print(f"Error: {str(e)}")
    import traceback
    traceback.print_exc()
    print("Pipeline execution failed")


def compare_disease_models(config):
    """Compare disease models with comprehensive progress tracking"""
    print("\n" + "="*50)
    print("Disease Model Comparison with Progress Tracking")
    print("="*50)

    # Load dataset and metadata
    rice_dataset = RiceDiseaseDataset(config)
    class_names = rice_dataset.class_names
    num_classes = len(class_names)

    # Create test dataset with progress
    print("\nLoading test dataset...")
    test_ds = keras.utils.image_dataset_from_directory(
        os.path.join(config['preprocessed_data_dir']),
        label_mode='int',
        batch_size=config['batch_size'],
        image_size=config['img_size'],
        shuffle=False,
        seed=config['random_state']
    ).prefetch(tf.data.AUTOTUNE)

    # Get true labels
    y_true = np.concatenate([y for x, y in tqdm(test_ds, desc="Loading labels")], axis=0)

    # Find model weights
    model_dir = os.path.join(config['output_dir'], 'models')
    weight_files = [f for f in os.listdir(model_dir)
                   if f.endswith('_best_weights.weights.h5')
                   and 'variety' not in f
                   and 'age' not in f]

    # Model builder mapping
    model_builders = {
        'densenet201': build_densenet201_with_cbam,
        'inceptionresnetv2': build_inceptionresnetv2_with_cbam,
        'xception': build_xception_with_cbam,
        'inceptionv3': build_inceptionv3_with_cbam
    }

    # Comparison storage
    comparison_data = []
    all_metrics = {}

    # Main evaluation loop
    for weight_file in tqdm(weight_files, desc="Models", unit="model"):
        try:
            model_name = weight_file.replace('_best_weights.weights.h5', '')
            print(f"\n\033[1mEvaluating {model_name}\033[0m")

            # Load model with progress
            with tqdm(total=3, desc="Model Setup") as pbar:
                # Load architecture
                builder_fn = model_builders.get(model_name)
                if not builder_fn:
                    raise ValueError(f"No builder for {model_name}")
                pbar.update(1)

                # Build model
                model = builder_fn(num_classes, (*config['img_size'], 3))
                pbar.update(1)

                # Load weights
                weights_path = os.path.join(model_dir, weight_file)
                model.load_weights(weights_path)
                pbar.update(1)

            # Prediction phase
            y_pred = []
            y_proba = []
            with tqdm(test_ds, desc="Predicting", unit="batch", leave=False) as batch_pbar:
                for images, _ in batch_pbar:
                    preds = model.predict(images, verbose=0)
                    y_proba.extend(preds)
                    y_pred.extend(np.argmax(preds, axis=1))
                    batch_pbar.set_postfix({
                        "processed": f"{len(y_pred)}/{len(y_true)}"
                    })

            # Convert to arrays
            y_pred = np.array(y_pred)
            y_proba = np.array(y_proba)

            # Calculate metrics
            with tqdm(total=3, desc="Calculating Metrics") as metric_pbar:
                accuracy = accuracy_score(y_true, y_pred)
                metric_pbar.update(1)

                f1 = f1_score(y_true, y_pred, average='weighted')
                metric_pbar.update(1)

                y_true_bin = label_binarize(y_true, classes=np.arange(num_classes))
                roc_auc = roc_auc_score(y_true_bin, y_proba, multi_class='ovr')
                metric_pbar.update(1)

            # Store results
            metrics = {
                'accuracy': accuracy,
                'f1_score': f1,
                'roc_auc': roc_auc
            }
            all_metrics[model_name] = metrics
            comparison_data.append({
                'Model': model_name,
                'Accuracy': accuracy,
                'F1 Score': f1,
                'ROC-AUC': roc_auc
            })

            # Plotting
            with tqdm(total=1, desc="Generating Plots") as plot_pbar:
                cm = confusion_matrix(y_true, y_pred)
                plt.figure(figsize=(12, 10))
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                           xticklabels=class_names,
                           yticklabels=class_names)
                plt.title(f'{model_name} Confusion Matrix')
                plt.ylabel('True Label')
                plt.xlabel('Predicted Label')
                plt.xticks(rotation=45, ha='right', fontsize=8)
                plt.yticks(rotation=0, fontsize=8)
                plt.tight_layout()
                plt.savefig(os.path.join(config['output_dir'], 'plots',
                                        f'{model_name}_confusion.png'))
                plt.close()
                plot_pbar.update(1)

            # Cleanup
            del model
            keras.backend.clear_session()

        except Exception as e:
            print(f"\n\033[31mError in {model_name}: {str(e)}\033[0m")
            continue

    # Final output
    print("\n\033[1mComparison Results:\033[0m")
    comparison_df = pd.DataFrame(comparison_data)
    print(tabulate(comparison_df, headers='keys', tablefmt='psql', showindex=False))

    # Save results
    metrics_path = os.path.join(config['output_dir'], 'metrics', 'model_comparison.json')
    with open(metrics_path, 'w') as f:
        json.dump(all_metrics, f, indent=4)

    # Visualization
    plt.figure(figsize=(15, 6))
    metrics = ['Accuracy', 'F1 Score', 'ROC-AUC']
    x = np.arange(len(comparison_df))
    width = 0.25

    for i, metric in enumerate(metrics):
        plt.bar(x + i*width, comparison_df[metric], width, label=metric)

    plt.title('Model Performance Comparison')
    plt.ylabel('Score')
    plt.xticks(x + width, comparison_df['Model'], rotation=45, ha='right')
    plt.ylim(0, 1.05)
    plt.legend(loc='lower right')
    plt.tight_layout()
    plt.savefig(os.path.join(config['output_dir'], 'plots', 'model_comparison.png'))
    plt.close()

    return comparison_df

# model_comparison = compare_disease_models(CONFIG)